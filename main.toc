\contentsline {chapter}{\numberline {1}Philosophical Insights of Vector Spaces}{1}{}%
\contentsline {section}{\numberline {1.1}Understanding Closure in \(\mathbb {R}^n\): Why Vector Spaces Are Chosen for Image Representation}{1}{}%
\contentsline {subsection}{\numberline {1.1.1}Meaning of Closure}{2}{}%
\contentsline {subsection}{\numberline {1.1.2}Why Closure Matters for Images}{2}{}%
\contentsline {subsection}{\numberline {1.1.3}How \(\mathbb {R}^n\) Ensures Closure}{2}{}%
\contentsline {section}{\numberline {1.2}Understanding Column Space and Its Relevance in Deep Learning}{3}{}%
\contentsline {chapter}{\numberline {2}Learning Feature Invariance}{5}{}%
\contentsline {paragraph}{Example 1: Sentiment Analysis}{5}{}%
\contentsline {section}{\numberline {2.1}Named Entity Recognition (NER)}{6}{}%
\contentsline {paragraph}{(a) Bag-of-Words (BoW) Embedding.}{8}{}%
\contentsline {paragraph}{(b) Position-Sensitive (Sequential) Embedding.}{8}{}%
\contentsline {chapter}{\numberline {3}Image as Matrix}{15}{}%
\contentsline {section}{\numberline {3.1}Historical Evolution of Images as Vectors}{15}{}%
\contentsline {subsection}{\numberline {3.1.1}Early Image Digitization (1950s--1970s)}{15}{}%
\contentsline {subsection}{\numberline {3.1.2}Pattern Recognition and Statistical Methods (1970s--1990s)}{16}{}%
\contentsline {subsection}{\numberline {3.1.3}Deep Learning Era (2000s--Present)}{16}{}%
\contentsline {subsection}{\numberline {3.1.4}Summary Timeline}{16}{}%
\contentsline {section}{\numberline {3.2}From Images to Vectors: Justifying Linear Operations in Image Processing}{16}{}%
\contentsline {subsection}{\numberline {3.2.1}Why Vector Representation is Meaningful}{17}{}%
\contentsline {subsection}{\numberline {3.2.2}Why Vector Operations Make Sense for Images}{18}{}%
\contentsline {subsection}{\numberline {3.2.3}Why Linear Algebra is Applicable to Image Processing}{18}{}%
\contentsline {subsection}{\numberline {3.2.4}Conclusion}{19}{}%
\contentsline {section}{\numberline {3.3}Pixels, Perception, and the Problem of Meaning}{19}{}%
\contentsline {section}{\numberline {3.4}Vectors as Movements in Space}{20}{}%
\contentsline {section}{\numberline {3.5}The Philosophical Necessity of Linear Transformation in Image Processing}{22}{}%
\contentsline {section}{\numberline {3.6}Matrices Support Transformation}{23}{}%
\contentsline {section}{\numberline {3.7}Controlled Transformations}{26}{}%
\contentsline {section}{\numberline {3.8}The Philosophy of Composition}{27}{}%
\contentsline {subsection}{\numberline {3.8.1}Why Convolutional Kernels Have Shape}{28}{}%
\contentsline {section}{\numberline {3.9}Images as Structured Tensors}{29}{}%
\contentsline {section}{\numberline {3.10}Contextualizing Semantic Meaning}{30}{}%
\contentsline {paragraph}{Example of Structural Information.}{30}{}%
\contentsline {paragraph}{Example of Syntactic Information.}{31}{}%
\contentsline {section}{\numberline {3.11}The Role of the Convolutional Layer}{32}{}%
\contentsline {section}{\numberline {3.12}Emergence of Semantics Through Optimization}{34}{}%
\contentsline {chapter}{\numberline {4}Common Python Code}{36}{}%
\contentsline {section}{\numberline {4.1}Python Data Types and Cheat Sheet}{36}{}%
\contentsline {section}{\numberline {4.2}Typical Function Categories in Python Programming}{37}{}%
\contentsline {section}{\numberline {4.3}The Pattern of Sequence Padding and Length Normalization}{42}{}%
\contentsline {section}{\numberline {4.4}Building Token Frequencies with \texttt {collections.Counter}}{44}{}%
\contentsline {paragraph}{Motivation.}{44}{}%
\contentsline {subsection}{\numberline {4.4.1}What is \texttt {Counter}?}{45}{}%
\contentsline {paragraph}{Explanation.}{45}{}%
\contentsline {subsection}{\numberline {4.4.2}Using \texttt {Counter.update()}}{45}{}%
\contentsline {paragraph}{Explanation.}{46}{}%
\contentsline {subsection}{\numberline {4.4.3}Applying to Tokenized Text Data}{46}{}%
\contentsline {paragraph}{Explanation.}{46}{}%
\contentsline {section}{\numberline {4.5}Understanding \texttt {torch.zeros()} in PyTorch}{47}{}%
\contentsline {subsection}{\numberline {4.5.1}Function Signature}{47}{}%
\contentsline {paragraph}{Common Use Cases}{48}{}%
\contentsline {chapter}{\numberline {5}Spatially Local Pattern}{49}{}%
\contentsline {chapter}{\numberline {6}Subtraction as a Fundamental Tool for Change Detection}{50}{}%
\contentsline {section}{\numberline {6.1}Introduction}{50}{}%
\contentsline {section}{\numberline {6.2}Mathematical and Logical Basis of Subtraction}{50}{}%
\contentsline {section}{\numberline {6.3}Subtraction in Temporal and Logical Structures}{51}{}%
\contentsline {section}{\numberline {6.4}Subtraction in Visual and Spatial Domains}{52}{}%
\contentsline {section}{\numberline {6.5}Geometric Reasoning and Directionality of Change}{52}{}%
\contentsline {section}{\numberline {6.6}Subtraction in Natural Language Processing}{53}{}%
\contentsline {paragraph}{1. What do we mean by \textquotedblleft semantic\textquotedblright ?}{55}{}%
\contentsline {paragraph}{2. What is an embedding?}{55}{}%
\contentsline {paragraph}{3. What does the subtraction $A - B$ mean in this context?}{55}{}%
\contentsline {paragraph}{4. Where does this semantic encoding come from?}{56}{}%
\contentsline {paragraph}{5. Summary Table}{56}{}%
\contentsline {section}{\numberline {6.7}Conclusion}{57}{}%
